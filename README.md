This project is “Creating ETL Data Pipelines with BashOperator using Apache Airflow” and “Creating Streaming Data Pipelines using Kafka”. 
To achieve the result.

As a Data Engineer at a data analytics consulting company and been assigned a project to decongest the national highways by analyzing the road traffic data from different toll plazas. Each highway is operated by a different toll operator with a different IT setup that uses different file formats. The task is to collect data available in different formats and consolidate it into a single file.

A DAG was created which comprised of the following processes:

•	Extract data from CSV, TSV, and fixed width files
•	Transform extracted data
•	Load transformed data into the staging area.
•	Submit, unpause, and monitor a DAG.
•	Create a topic in Kafka
•	Download and customize a streaming data consumer
•	Verify that streaming data has been collected in a database table
